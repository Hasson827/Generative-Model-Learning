# 线性回归模型

## 基本模型

### 统计决策基本模型

用$\boldsymbol{x} = (x_{1}, x_{2}, \dots, x_{d})^{\top}\in \R^{d}$表示输入数据的特征向量，$y\in\R$表示输出。数据的真实分布记为$p(\boldsymbol{x},y)$。有监督学习的目标是寻找预测函数$f:\boldsymbol{x}\mapsto y$。为了评价函数的性能，假设有一个损失函数$\mathcal{l}(y,f(\boldsymbol{x}))$。一个自然的选择$f$的标准是最小化在数据上的平均（期望）损失：
$$
R(f) = \mathbb{E}_{p(\boldsymbol{x},y)}[\mathcal{l}(y,f(\boldsymbol{x}))]
$$
具体地，当考虑固定的输入数据$\boldsymbol{x}$时，可以得到对应预测值$f(\boldsymbol{x})$地平均（期望）损失：
$$
R(f(\boldsymbol{x})) = \mathbb{E}_{p(y|\boldsymbol{x})}[\mathcal{l}(y,f(\boldsymbol{x}))]
$$
因此，最优的单点预测为$\hat{y} = f(\boldsymbol{x}) = \arg\min_{z\in\R}\mathbb{E}_{p(y|\boldsymbol{x})}[\mathcal{l}(y,z)]$，即在给定$\boldsymbol{x}$的情况下，使得损失函数最小的$z$的取值，即为$y$的单点预测值。

通过简单分析，可以推导出如下常见的特例：

1. 当损失函数为平方误差$\mathcal{l}(y,f(\boldsymbol{x})) = (y-f(\boldsymbol{x}))^{2}$时，最优的预测函数为$f(\boldsymbol{x}) = \mathbb{E}_{p}[Y|\boldsymbol{x}]$，即给定$\boldsymbol{x}$时的条件期望。
2. 当损失函数为绝对误差$\mathcal{l}(y,f(\boldsymbol{x})) = |y-f(\boldsymbol{x})|$时，最优的预测函数为$f(\boldsymbol{x}) = \text{median}(Y|\boldsymbol{x})$，即给定$\boldsymbol{x}$时的条件中位数。

在实际问题中，真实的数据分布$p(\boldsymbol{x},y)$是未知的，我们能获得的是从数据分布中采样得到的一些训练样本。通过训练数据，可以构造一个经验分布。

**定义1（经验分布）**：给定训练集$\mathcal{D} = \left\{ (\boldsymbol{x}_{i},y_{i}) \right\}_{i=1}^{N}$，其中$(\boldsymbol{x}_{i},y_{i})\sim p(\boldsymbol{x},y)$是独立采样的数据点，其经验分布为
$$
\tilde{p}(\boldsymbol{x},y) = \frac{1}{N}\sum_{i=1}^{N}\delta_{(\boldsymbol{x}_{i},y_{i})}(\boldsymbol{x},y)
$$
其中$\delta_{a}(b) = 1$当且仅当$a=b$，否则等于0

将真实数据分布$p(\boldsymbol{x},y)$替换成经验分布$\tilde{p}$，就得到了具体的可以计算的估计。

### 线性回归及最小二乘法

线性回归模型假设输入数据$\boldsymbol{x}\in\R^{d}$和输出$f(\boldsymbol{x})\in\R$之间具有线性关系：
$$
f(\boldsymbol{x}) = \boldsymbol{w}^{\top}\boldsymbol{x}+b
$$
其中$\boldsymbol{w}^{\top}\boldsymbol{x}$表示参数向量$\boldsymbol{w}^{\top}\in\R^{d}$与输入数据向量$\boldsymbol{x}$的点积，$b$为偏置项(Offset)。为了简化符号，我们把偏置项$b$吸收到$\boldsymbol{w}$向量中——通过将$\boldsymbol{x}$扩展一维，取值为单位1，同样把$\boldsymbol{w}$扩展一维，值为$b$。

给定训练集$\mathcal{D} = \left\{ (\boldsymbol{x}_{i},y_{i}) \right\}_{i=1}^{N}$，线性回归模型的目标是通过给定的训练数据$\mathcal{D}$估计未知参数$\hat{\boldsymbol{w}}$，使得模型在给定一个新的观测数据$\boldsymbol{x}$，模型可以给出一个对应的预测$\hat{y} = \hat{\boldsymbol{w}}^{\top}\boldsymbol{x}$。

学习参数$\boldsymbol{w}$的一种经典方法是最小二乘法，其目标是最小化平方误差：
$$
\min_{\boldsymbol{w}}{\frac{1}{N}\sum_{i=1}^{N}{(y_{i} - \boldsymbol{w}^{\top}\boldsymbol{x}_{i})^{2}}}
$$
利用优化理论对目标函数$L(\boldsymbol{w})$求梯度并使其为$\boldsymbol{0}$:
$$
\nabla_{\boldsymbol{w}}L(\boldsymbol{w}) = {\frac{1}{N}\sum_{i=1}^{N}{(\boldsymbol{w}^{\top}\boldsymbol{x}_{i}-y_{i})\boldsymbol{x}_{i}^{\top}}} = \boldsymbol{0}
$$
由此，通过化简便可以得到模型参数$\boldsymbol{w}$的最优解：
$$
\hat{\boldsymbol{w}}_{\text{ls}} = (\boldsymbol{X}^{\top}\boldsymbol{X})^{-1}\boldsymbol{X}^{\top}\boldsymbol{y}
$$
其中$\boldsymbol{X}$是一个$N$行$d$列的输入数据矩阵，每一行表示一组观测到的数据点，一共有$d$个不同的特征维度。$\boldsymbol{y}$中与之相对应的一行就是这一组数据的标签，同样一共有$N$行。

对于给定的任意输入数据$\boldsymbol{x}_{*}$，线性回归模型的预测为：
$$
\hat{y}_{*} = \boldsymbol{x}_{*}^{\top}\hat{\boldsymbol{w}}_{\text{ls}} = \boldsymbol{x}_{*}^{\top}(\boldsymbol{X}^{\top}\boldsymbol{X})^{-1}\boldsymbol{X}^{\top}\boldsymbol{y}
$$
前面介绍过，由于训练集$\mathcal{D}$是从数据分布中随机采样的，估计$\hat{\boldsymbol{w}}_{\text{ls}}$也具有随机性，因此可以进一步分析估计$\hat{\boldsymbol{w}}_{\text{ls}}$的均方差：
$$
\text{MSE}(\hat{\boldsymbol{w}}_{\text{ls}}) = \mathbb{E}\left[ (\hat{\boldsymbol{w}}_{\text{ls}} - \boldsymbol{w})^{2} \right] = \text{Var}(\hat{\boldsymbol{w}}_{\text{ls}})+(\mathbb{E}[\hat{\boldsymbol{w}}_{\text{ls}}]-\boldsymbol{w})^{2}
$$
这里的期望和方差都是相对于数据分布$p(\boldsymbol{x},y)$。该式称为“偏差-方差”分解(Bias-Variance Decomposition)。从该分解中可以看到，如果要寻找一个均方误差最优的估计，需要同时兼顾方差和偏差，并且二者之间存在某种折中，这种线性称为“偏差-方差”折中(Bias-Variance Tradeoff)。

### 概率模型及最大似然估计

最小二乘法存在一个等价的概率描述。具体地，对于给定的训练数据$(\boldsymbol{x}_{i},y_{i})$，输入数据和输出之间的关系可以通过一个加性噪声模型刻画：
$$
y(\boldsymbol{x}) = f(\boldsymbol{x})+\epsilon
$$
其中$\epsilon$为误差变量，也称为残差(Residual Error)，表示实际的输出与线性预测之间的误差。在线性回归模型中，$f(\boldsymbol{x}) = \boldsymbol{w^{\top}x}$为线性函数。在自然界中，许多随机误差都服从正态分布。一般假设$\epsilon$服从均值为0的正态分布，记为$\epsilon\sim\mathcal{N}(0,\sigma^{2})$，其中方差不随$\boldsymbol{x}$的改变而改变。

可以从概率的角度看待这个线性噪声模型。具体而言，由于$y$的不确定性全部是由每一点$\boldsymbol{x}$的残差引起的，从上式可以得到$y-\boldsymbol{w^{\top}x} = \epsilon\sim\mathcal{N}(0,\sigma^{2})$，进一步可以得到：
$$
p(y|\boldsymbol{x,\theta}) = \mathcal{N}(y|\mu(\boldsymbol{x}),\sigma^{2}) = \mathcal{N}(y|\boldsymbol{w^{\top}x},\sigma^{2})
$$
其中$\mu(\boldsymbol{x}) = \boldsymbol{w^{\top}x}$为正态分布的均值。因此，给定输入向量$\boldsymbol{x}$和模型中的各种参数，$y$的分布是一个正态分布，其均值是对于$\boldsymbol{x}$的线性预测。

在线性回归模型的设定中，通常假设噪声方差是给定的。我们求解参数$\boldsymbol{w}$的估计$\hat{\boldsymbol{w}}$。在估计$\hat{\boldsymbol{w}}$时，通常采用最大似然估计(MLE)，其优化对数似然函数$\mathcal{L}(\boldsymbol{w}) = \log{p(\mathcal{D}|\boldsymbol{w})}$。利用数据的独立分布特性，对数似然函数$\mathcal{L}(\boldsymbol{w})$可以写成：
$$
\mathcal{L}(\boldsymbol{w}) = \log{p(\mathcal{D}|\boldsymbol{w})} = \sum_{i=1}^{N}{\log{p(y_{i}|\boldsymbol{x}_{i},\boldsymbol{w})}}
$$
为了得到参数的估计$\hat{\boldsymbol{w}}$，需要求出对数似然函数对于各个参数分量的偏导数，使得偏导数为0的参数表示一个函数的局部极大(或极小)点。在具有凸性的问题中往往这样的参数就是全局最优解。

具体地，将线性回归模型的概率定义式代入对数似然函数式，得到对数似然函数的具体形式：
$$
\mathcal{L}(\boldsymbol{w}) = \sum_{i=1}^{N}{\log{\left[ \frac{1}{\sqrt{2\pi}\sigma}\exp\left( -\frac{1}{2\sigma^{2}}\left( y_{i} - \boldsymbol{w^{\top}x}_{i} \right)^{2} \right) \right]}}
$$
适当化简，可以得到：
$$
\mathcal{L}(\boldsymbol{w}) = -\frac{1}{2\sigma^{2}}\sum_{i=1}^{N}{\left( y_{i} - \boldsymbol{w^{\top}x}_{i} \right)^{2}}-\frac{N}{2}\log{(2\pi\sigma^{2})}
$$
其中后一项在给定数据的前提下为定值，我们只需要重点关心前一项中模型参数$\boldsymbol{w}$的估计量。可以观察到最大化似然$\mathcal{L}(\boldsymbol{w})$等价于最小二乘法。

### 带基函数的线性回归

线性回归模型所能够表达的函数空间仅仅包含了简单的线性函数。但在实际问题中，输出变量和输入数据之间可能存在非线性关系，为此，需要将线性回归模型进行适当扩展。

一种直观的扩展是引入基函数(Base Function)的概念。基函数是函数空间中一组特定的函数，这个函数空间中的任意连续函数都可以表示为这组基函数的线性组合。具体地，可以对上面定义式中的$\boldsymbol{x}$先做一个非线性的基函数变换$\boldsymbol{\phi}(\boldsymbol{x}) = \left( \phi_{1}(\boldsymbol{x}),\phi_{2}(\boldsymbol{x}),\dots,\phi_{d}(\boldsymbol{x}) \right)^{\top}$，再做同样的线性回归。修改之后的定义式如下：
$$
p(y|\boldsymbol{x,\theta}) = \mathcal{N}(y|\boldsymbol{w^{\top}\phi}(\boldsymbol{x}),\sigma^{2})
$$
这里同样假设噪声方差$\sigma^{2}$是给定的。

## 正则化线性回归

在实际应用中，最小二乘线性回归模型可能过度拟合数据中的噪声。如果$x$的取值与给定的训练数据稍微有所偏差，利用该曲线“预测”的值将相对“真实值”有大幅变动，也与近邻训练数据的观察值相差较大。这种现象称为过拟合(Over-Fitting)。对于线性模型，过拟合的一种常见展示形式是权值$\boldsymbol{w}$出现“发散”，即绝对值过大。

克服过拟合的一种常见形式是引入正则化项，达到更好的“偏差-方差”均衡。这里介绍两种常见的正则化方法——岭回归(Ridge Regression)和Lasso回归。

### 岭回归

岭回归求解如下问题：
$$
\hat{\boldsymbol{w}}_{\text{ridge}} = \arg{\min_{\boldsymbol{w}}}\frac{1}{N}\sum_{i=1}^{N}{\left( y_{i} - \boldsymbol{w^{\top}x}_{i} \right)^{2}}+\lambda\| \boldsymbol{w} \|_{2}^{2}
$$
其中$\| \boldsymbol{w} \|_{2}^{2} = \sum_{1}^{d}w_{i}^{2}$是参数向量$\boldsymbol{w}$的$L_{2}$范式的平方。$L_{2}$正则化项起到收缩参数的作用——$\boldsymbol{w}$的每个元素绝对值不能太大，否则正则化项(也称为惩罚项)会变大。$\lambda$是一个非负的系数，作用是控制惩罚项的大小。若$\lambda$较大，则对$\boldsymbol{w}$的收缩较严格，最终得到的参数绝对值将会较小。因此，为了最小化目标函数，岭回归需要在训练数据的均方差和正则化项之间找到一个折中的结果。通过求解可以得到岭回归的最优解：
$$
\hat{\boldsymbol{w}}_{\text{ridge}} = \left( \lambda\boldsymbol{I}_{d}+\boldsymbol{X^{\top}X} \right)^{-1}\boldsymbol{X^{\top}y}
$$
其中$\boldsymbol{I}_{d}$是$d\times d$的单位矩阵。比较最小二乘估计$\hat{\boldsymbol{w}}_{\text{ls}} = (\boldsymbol{X}^{\top}\boldsymbol{X})^{-1}\boldsymbol{X}^{\top}\boldsymbol{y}$，可以看出正则化项对估计结果的影响为在括号内多了一个与惩罚项相关的矩阵$\lambda\boldsymbol{I}_{d}$。从数值优化上，矩阵$\left( \lambda\boldsymbol{I}_{d}+\boldsymbol{X^{\top}X} \right)$一定是可逆的；而矩阵$\boldsymbol{X^{\top}X}$却有可能不知满秩的，也不可逆。事实上，数值稳定性是岭回归的初衷之一。

岭回归的等价描述是：
$$
\hat{\boldsymbol{w}}_{\text{ridge}} = \arg{\min_{\boldsymbol{w}}}\frac{1}{N}\sum_{i=1}^{N}{\left( y_{i} - \boldsymbol{w^{\top}x}_{i} \right)^{2}}
\\[10pt]
\text{s.t. }\| \boldsymbol{w} \|_{2}^{2}\le t
$$
这里的等价性是指：给定一个$\lambda$，存在一个$t$，使得两者的解相同；反之亦然。这种等价的、受约束的描述形式在概念上具有一些良好的性质：

1. 它显式表达了$L_{2}$范数对参数的约束
2. $\hat{\boldsymbol{w}}_{\text{ridge}}$可以看作$\hat{\boldsymbol{w}}_{\text{ls}}$在$L_{2}$范数球上的投影，即若$\| \boldsymbol{w} \|_{2}^{2}\le t$，则$\hat{\boldsymbol{w}}_{\text{ridge}} = \hat{\boldsymbol{w}}_{\text{ls}}$；否则，$\hat{\boldsymbol{w}}_{\text{ridge}}$是$\hat{\boldsymbol{w}}_{\text{ls}}$在半径为$\sqrt{t}$的球上的投影。

值得注意的是，在上述正则化项中，我们一般不对偏置项$w_{0}$做惩罚，这是因为：如果惩罚$w_{0}$，求得的结果将依赖于$y$的原点——对于线性回归模型，如果对每个训练样本$y_{i}$平移大小为$c$的量，我们将期待求得的预测$\hat{y}_{i}$也相应进行简单平移大小为$c$的量；但是，如果对$w_{0}$进行惩罚，这种简单的平移关系将不再成立。显式将$w_{0}$分开写的完整形式如下。
$$
\hat{w}_{0},\hat{\boldsymbol{w}}_{\text{ridge}} = \arg{\min_{w_{0},\boldsymbol{w}}}\frac{1}{N}\sum_{i=1}^{N}{\left( y_{i} - w_{0} - \boldsymbol{w^{\top}x}_{i} \right)^{2}}+\lambda\| \boldsymbol{w} \|_{2}^{2}
$$
通过求解，实际训练时，可以先对$y_{i}$和$\boldsymbol{x}_{i}$做“中心化”预处理，即将每个$y_{i}$减去$\bar{y}$，每个$\boldsymbol{x}_{i}$减去$\bar{\boldsymbol{x}}$；处理之后，可以忽略掉$w_{0}$，直接求解$\hat{\boldsymbol{w}}_{\text{ridge}}$；在预测阶段，需要将预测的结果加上$(\bar{y}-\hat{\boldsymbol{w}}_{\text{ridge}}^{\top}\bar{\boldsymbol{x}})$。

### Lasso回归

Lasso(least absolute shrinkage and selection operator，最小绝对收缩与选择算子)是一种与岭回归很像，但也存在本质区别的线性回归模型，在信号处理领域被称为(去噪)基追踪(Basis Pursuit)。具体地，Lasso求解如下问题。
$$
\hat{\boldsymbol{w}}_{\text{Lasso}} = \arg{\min_{\boldsymbol{w}}}\frac{1}{N}\sum_{i=1}^{N}{\left( y_{i} - \boldsymbol{w^{\top}x}_{i} \right)^{2}}+\lambda\| \boldsymbol{w} \|_{1}
$$
其中$\| \boldsymbol{w} \|_{1} = \sum_{i=1}^{d}|w_{i}|$是$L_{1}$范数。同样，为了简简洁，这里没有显式写出$w_{0}$，正则化也不定义在$w_{0}$上，实际上$w_{0}$的最优解同样是$\bar{y}-\boldsymbol{w^{\top}\bar{x}}$。此外，与岭回归类似，上式可以等价写成受约束的问题：
$$
\hat{\boldsymbol{w}}_{\text{Lasso}} = \arg{\min_{\boldsymbol{w}}}\frac{1}{N}\sum_{i=1}^{N}{\left( y_{i} - \boldsymbol{w^{\top}x}_{i} \right)^{2}}
\\[10pt]
\text{s.t. }\| \boldsymbol{w} \|_{1}\le t
$$
基于该受约束的形式，可以直观上将Lasso的最优解堪称最小二乘的最优解$\hat{\boldsymbol{w}}_{\text{ls}}$在$L_{1}$范数球上的投影。令$t_{0} = \| \hat{\boldsymbol{w}}_{\text{ls}} \|_{1}$，若$t\ge t_{0}$，则$\hat{\boldsymbol{w}}_{\text{Lasso}} = \hat{\boldsymbol{w}}_{\text{ls}}$；否则，$\hat{\boldsymbol{w}}_{\text{Lasso}}$是$\hat{\boldsymbol{w}}_{\text{ls}}$的一个投影；在一些情况下，投影后的$\hat{\boldsymbol{w}}_{\text{Lasso}}$落在坐标轴上，因此，部分维度的权重取值为0，在线性模型中，这等效于去处了该维度对应的特征，从而Lasso可以实现特征选择的作用。

由于$L_{1}$范数不可导，Lasso与岭回归的一个显著不同在于其优化问题没有简单的解析解，为此，多种凸优化的求解算法可以解决，包括交替下降、次梯度、近端梯度下降等方法。这里主要介绍近端梯度下降法。近端梯度下降法适合求解如下一般形式的问题：
$$
\min_{\boldsymbol{w}}{f(\boldsymbol{w})+h(\boldsymbol{w})}
$$
其中$f(\boldsymbol{w})$是可导的，$h(\boldsymbol{w})$为凸函数。近端梯度下降法依赖一个近端映射(也称为近端算子)，具体地，对于凸函数$h(\boldsymbol{x})$，其近端映射为
$$
\text{Prox}_{h}(\boldsymbol{w}) = \arg{\min_{\boldsymbol{u}}{\left( h(\boldsymbol{u})+\frac{1}{2}\| \boldsymbol{u} - \boldsymbol{w} \|_{2}^{2} \right)}}
$$
近端算子的含义是找一个点，使得函数$h$的取值尽量小，同时，尽量接近给定的点$\boldsymbol{w}$。基于近端算子，近端梯度下降法迭代更新模型参数如下。
$$
\boldsymbol{w}_{t+1} = \text{Prox}_{h,\eta_{t}}\left(\boldsymbol{w}_{t} - \eta_{t}\nabla f(\boldsymbol{w}_{t})\right)
$$
其中$\text{Prox}_{h,\eta}(\boldsymbol{w}) = \arg{\min_{\boldsymbol{u}}{\left( h(\boldsymbol{u})+\frac{1}{2\eta}\| \boldsymbol{u} - \boldsymbol{w} \|_{2}^{2} \right)}}$，$\eta_{t}$为迭代步长(学习率)。设定初始值$\boldsymbol{w}_{0}$，不断迭代，直至收敛。

### $L_{p}$范数正则化的线性回归

考虑更一般的$L_{p}$范数正则化项$\| \boldsymbol{w} \|_{p} = \sum_{i = 1}^{d}|w_{i}|^{p}$，其中$p\ge0$，对应的正则化线性回归模型为
$$
\hat{\boldsymbol{w}}_{\text{lp}} = \arg{\min_{\boldsymbol{w}}}\frac{1}{N}\sum_{i=1}^{N}{\left( y_{i} - \boldsymbol{w^{\top}x}_{i} \right)^{2}}
\\[10pt]
\text{s.t. }\| \boldsymbol{w} \|_{p}\le t
$$
根据$p$的取值，几种情况如下。

1. 当$p=0$是，$\|\boldsymbol{w}\|_{p}$为向量$\boldsymbol{w}$中的非零元素个数，该正则化项将从特征向量中“硬性”选择不超过$t$个特征，这是一个NP难的组合优化问题，近似算法包括贪心搜索法、迭代硬约束法等。
2. 当$0\lt p\lt1$时，与$L_{1}$范数类似，该集合存在“尖锐”的顶点，因此，也可以用来进行稀疏学习选择特征。
3. 当$p\gt1$时，该集合是一个凸集，但与$L_{2}$正则化类似，它们不存在“尖锐”的顶点，因此，只有收缩$\boldsymbol{w}$的作用，不能用于特征选择。

## 贝叶斯线性回归

如前所述，最小二乘法可以看成对概率模型的最大似然估计，存在过拟合的风险；同时，为了对估计的质量进行刻画，需要考虑多次重复性实验(即对多次的训练数据集$\mathcal{D}$进行平均)。这种“重复实验”的范式在实际应用中存在不足，首先，多次重复实验带来更多的计算代价。其次，如果有多个训练集，更加有效的方式应该是将其合并成一个更大的数据集，更加充分的训练模型。贝叶斯推断提供了另外一种思路，在给定一个数据集的情况下，刻画模型自身的不确定性，可以有效避免过拟合。同时，带有正则化项的回归模型可以看作贝叶斯推断的特例。

贝叶斯推断的基本思想是将未知变量看成随机变量，在观察数据之前，对变量的取值用一个先验分布刻画。在观察到数据之后，利用贝叶斯定理对先验分布进行更新，得到后验分布。一线性回归为例，模型的参数$\boldsymbol{w}$是未知的。为此，假设先验分布$p(\boldsymbol{w})$，给定训练集$\mathcal{D}$，贝叶斯后验分布为
$$
p(\boldsymbol{w}|\mathcal{D}) = \frac{p(\mathcal{D}|\boldsymbol{w})\cdot p(\boldsymbol{w})}{p(\mathcal{D})}
$$
其中$p(\mathcal{D}|\boldsymbol{w})$是描述数据生成的似然函数，$p(\mathcal{D})$为“证据”。

### 最大后验分布估计

从贝叶斯的角度，正则化可以看成对后验分布的MAP估计，即最大后验估计(Maximum a Posterior, MAP)，其一般形式如下：
$$
\hat{\boldsymbol{w}}_{\text{MAP}} = \arg{\max_{\boldsymbol{w}}{ \log{p(\mathcal{D}|\boldsymbol{w})} + \log{p(\boldsymbol{w})} }}
$$
这里忽略了与$\boldsymbol{w}$无关的项$-\log{p(\mathcal{D})}$。对于线性回归模型，数据的似然函数是一个高斯分布。如果先验分布是均匀分布，MAP估计退化为最大似然估计。通常情况下，我们选择高斯分布作为先验分布：
$$
p(\boldsymbol{w}) = \prod_{i=1}^{d}{\mathcal{N}(w_{i}|0,\tau^{2})}
$$
这里设置均值为0，表示在得到数据之前我们倾向于认为各个参数$w_{i}$越接近0，可能性越大。将上式代入MAP的一般形式，可以得到具体的MAP估计：
$$
\hat{\boldsymbol{w}}_{\text{MAP}} = \arg{\max_{\boldsymbol{w}}{ \sum_{i=1}^{N}{\mathcal{N}(y_{i}|\boldsymbol{w^{\top}x}_{i},\sigma^{2})} + \sum_{i=1}^{d}{\log{\mathcal{N}(w_{j}|0,\tau^{2})}} }}
$$
在设定合适的超参数$\sigma^{2}$和$\tau^{2}$的情况下，该问题与岭回归等价。因此，岭回归实际上是一种特殊贝叶斯模型的MAP估计。类似地，Lasso实际上也是一种MAP估计，其中先验分布设为拉普拉斯分布：
$$
p(\boldsymbol{w}) = \prod_{i=1}^{d}{\frac{1}{2b}\exp{\left( -\frac{|w_{i} - \mu|}{b} \right)}}
$$
其中均值$\mu\in\R$，$b\gt0$为尺度参数。在Lasso回归中，均值设为0。相比于高斯分布，拉普拉斯分布具有更加“平缓”的尾部。事实上，拉普拉斯分布可以写成无穷多个高斯分布的“混合”：
$$
p(w) = \frac{1}{2b}\exp{\left( -\frac{|w_{i} - \mu|}{b} \right)} = \int{p(w|\mu,\tau)p(\tau)d\tau}
$$
其中$p(\tau) = \frac{1}{2b^{2}}\exp\left( -\frac{w}{2b^{2}} \right)$为指数分布，$p(w|\mu,\tau) = \mathcal{N}(\mu,\tau)$为高斯分布。这种形式称为“尺度高斯混合”(Scale Mixture of Gaussians)，是一种很有用的表示方式，后文将利用该形式推导贝叶斯Lasso的采样算法。

### 贝叶斯预测分布

最大似然估计和MAP估计均是寻找某种目标函数下最优的单一参数，而贝叶斯推断可以充分利用后验分布$p(\boldsymbol{w}|\mathcal{D})$的信息。如何准确、高效地计算后验分布是贝叶斯推断的核心问题，通常情况下，也是一个困难的问题。

首先考虑相对简单的情况——先验分布和似然函数满足共轭性。具体地，对于线性回归模型，其似然函数$p(y|\boldsymbol{x})$是一个正态分布$\mathcal{N}(\mu,\sigma^{2})$，其中$\mu = \boldsymbol{w^{\top}x}$。假设先验分布也是高斯分布：
$$
p(\boldsymbol{w}) = \mathcal{N}(\boldsymbol{w}|\boldsymbol{w}_{0},\boldsymbol{V}_{0})
$$
其中$\boldsymbol{w}_{0}$为均值，$\boldsymbol{V}_{0}$为协方差矩阵。可以推出后验分布：
$$
p(\boldsymbol{w}|\boldsymbol{X},\boldsymbol{y},\sigma^{2})\propto\mathcal{N}(\boldsymbol{w}_{0},\boldsymbol{V}_{0})\mathcal{N}(\boldsymbol{y}|\boldsymbol{Xw},\sigma^{2}\boldsymbol{I}_{N}) = \mathcal{N}(\boldsymbol{w}|\boldsymbol{w}_{N},\boldsymbol{V}_{N})
$$
其中具体参数如下：
$$
\boldsymbol{w}_{N} = \boldsymbol{V}_{N}\boldsymbol{V}_{0}^{-1}\boldsymbol{w}_{0}+\frac{1}{\sigma^{2}}\boldsymbol{V}_{N}\boldsymbol{X}^{\top}\boldsymbol{y}
\\[10pt]
\boldsymbol{V}_{N} = \sigma^{2}\left( \sigma^{2}\boldsymbol{V}_{0}^{-1}+\boldsymbol{X}^{\top}\boldsymbol{X} \right)^{-1}
$$
在实际应用中，最常用的高斯先验分布为$\mathcal{N}(\boldsymbol{w}|\boldsymbol{0},\sigma^{2}\boldsymbol{I})$。

对于给定的测试数据$\boldsymbol{x}$，需要做出相应的预测$y$。在贝叶斯推断中，我们计算预测分布：
$$
p(y|\boldsymbol{x},\mathcal{D}) = \int{p(y|\boldsymbol{w},\boldsymbol{x},\mathcal{D})p(\boldsymbol{w}|\mathcal{D})d\boldsymbol{w}}
$$
其中$p(\boldsymbol{w}|\mathcal{D})$为后验分布。由前文所述，一般情况下，假设$p(y|\boldsymbol{w},\boldsymbol{x},\mathcal{D}) = p(y|\boldsymbol{w},\boldsymbol{x})$，即在给定模型参数的情况下，当前数据的分布于历史数据无关。这种假设通常是合理的，因为我们希望历史数据的信息都包含在模型$\boldsymbol{w}$的后验分布中。具体地，对于高斯先验的线性回归模型，可以得到：
$$
\begin{aligned}
p(y|\boldsymbol{x},\mathcal{D}) &= \int{\mathcal{N}(y|\boldsymbol{x^{\top}w},\sigma^{2})\mathcal{N}(\boldsymbol{w}|\boldsymbol{w}_{N},\boldsymbol{V}_{N})d\boldsymbol{w}}
\\[5pt]
&= \mathcal{N}(y|\boldsymbol{w}_{N}^{\top}\boldsymbol{x},\sigma_{N}^{2}(\boldsymbol{x}))
\end{aligned}
$$
其中$\sigma_{N}^{2}(\boldsymbol{x}) = \sigma^{2}+\boldsymbol{x^{\top}V}_{N}\boldsymbol{x}$。输出$y$的后验是一个正态分布，其均值是参数与输入的线性组合$\boldsymbol{w}_{N}^{\top}\boldsymbol{x}$，这与我们的直觉相符。而方差也是一个随着输入$\boldsymbol{x}$变化的量，而非一个定值。但$\sigma_{N}^{2}$由两部分组成：前一项考虑数据自身的方差(噪声)；而后一项考虑与$\mathcal{D}$中数据点的关系，属于模型的不确定性。在已经给定了数据点的$\boldsymbol{x}$福建对应的不确定性较小，后验分布的方差也较小；反之，距离数据点较远的$\boldsymbol{x}$处不确定性较大，得到的方差也会较大。此外，可以证明$\sigma_{N+1}^{2}(\boldsymbol{x})\le\sigma_{N}^{2}(\boldsymbol{x})$，且当$N\to\infin$时，$\sigma_{N}^{2}(\boldsymbol{x})$的第二项趋于0，即当训练样本足够多时，模型的不确定性逐渐消失。

### 贝叶斯模型选择

贝叶斯方法通过考虑模型不确定性，可以进行模型选择。假设有$L$个不同的模型可供选择：
$$
\left\{ \mathcal{M}_{i} \right\},\quad i = 1,2,\dots,L
$$
其中每个模型$\mathcal{M}_{i}$代表数据集$\mathcal{D}$上的一个分布。例如，在线性回归模型中，模型刻画分布为$p(y|\boldsymbol{x})$，使用不同阶的多项式函数对应了不同的概率分布。对一个给定的数据集，假设其服从候选模型(分布)的某一个，但不知道具体是哪个，因此需要模型选择。

贝叶斯方法通过先验和后验分布描述模型的不确定性。对于给定的数据$\mathcal{D}$，模型的后验分布为
$$
p(\mathcal{M}_{i}|\mathcal{D}) \propto p(\mathcal{M}_{i})\cdot p(\mathcal{D}|\mathcal{M}_{i})
$$
其中先验分布表达了对不同模型的偏好程度，第二项称为模型证据。在没有足够先验知识的情况下，一般假设不同模型具有相同的先验概率(即均匀先验分布)。因此，模型证据通常是我们更关心的，它描述了数据对不同模型的偏好程度。模型证据也称为边缘似然，因为对于参数化模型$\mathcal{M}_{i}$，它可以写成对未知参数$\boldsymbol{w}$进行边缘化得到的：
$$
\begin{aligned}
p(\mathcal{D}|\mathcal{M}_{i}) &= \int{p(\boldsymbol{w},\mathcal{D}|\mathcal{M}_{i})d\boldsymbol{w}}
\\[5pt]
&= \int{p(\boldsymbol{w}|\mathcal{M}_{i})p(\mathcal{D}|\boldsymbol{w},\mathcal{M}_{i})d\boldsymbol{w}}
\end{aligned}
$$
通常将两个模型的模型证据之比称为贝叶斯因子：
$$
\text{Bayes Factor} = \frac{p(\mathcal{D}|\mathcal{M}_{i})}{p(\mathcal{D}|\mathcal{M}_{j})}
$$
如果贝叶斯因子大于1，代表$\mathcal{M}_{i}$比$\mathcal{M}_{j}$更符合此数据集，反之亦然。

