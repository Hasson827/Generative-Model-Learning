# 统计推断

概率给我们提供了刻画数据产生过程以及特性分析的数学工具。但是在机器学习的实际应用中，我们往往只能观察到有限的数据样本，因此需要“逆向工程”，推断数据背后的规律（即产生过程），这个过程称为统计推断，也是机器学习的基本任务。

**定义1（统计推断）**：给定观测数据$x_{1},x_{2},\dots,x_{N}\sim F$，推断（估计或学习）概率分布$F$或其数字特征（如均值方差）。在进行统计推断时，需要对可行的$F$进行适当假设，即构建一个统计模型（简称模型）。统计模型一般分为参数化模型或非参数化模型。

**定义2（统计模型）**：统计模型是一组分布的集合$\mathcal{M}$。

**定义3（参数化模型）**：集合$\mathcal{M}$中的分布可以用有限多个参数进行表示，即
$$
\mathcal{M} = \left\{ p(x;\theta):\theta\in\Theta \right\}
$$
其中$\theta$是未知参数，$\Theta$是可行参数空间。例如，当假设一维数据$x$服从高斯分布时，相应的统计模型为
$$
\mathcal{M} = \left\{ \mathcal{N}(x;\mu,\sigma^{2}):\mu\in\R,\sigma\gt0 \right\}
$$
**定义4（非参数化模型）**：集合$\mathcal{M}$不能用有限个参数进行描述的模型或参数的个数为无限多个。

对于参数化模型，推断统计的目标是估计未知参数$\theta\in\Theta$；而对于非参数化模型，统计推断的目标是直接估计$F$。由于约束更少，因此后者一般更困难。

在统计推断中，有两类主要的方法——频率推断和贝叶斯推断。前者将参数$\theta$看作是未知但固定的，通过优化目标函数找到最优逼近$\hat{\theta}$，这种估计方法也称为点估计。而贝叶斯推断将未知参数看作随机变量，推断其后验分布$p(\theta|\mathcal{D})$。

## 最大似然估计(MLE)

最大似然估计（Maximum Likelihood Estimation, MLE）是统计学中常用的参数估计方法，其核心思想是：**在给定观测数据的情况下，寻找一组模型参数，使得该数据出现的概率（或概率密度）最大化**。设模型的概率密度函数为$p(x|\theta)$，其中$\theta\in\Theta$是未知参数向量，$\Theta$是参数空间。设$\mathcal{D} = \left\{x_{i}\right\}_{i=1}^{N}$是独立同分布的数据集，其联合概率密度函数为：
$$
\mathcal{L}(\theta) = \mathcal{L}(\mathcal{D}|\theta) = \prod_{i=1}^{N}{p(x_{i}|\theta)}
$$
$\mathcal{L}(\theta)$称为数据集$\mathcal{D}$的似然函数。$\theta$的最大似然估计为
$$
\hat{\theta} = \arg\max_{\theta}{\mathcal{L}(\theta)} = \arg\max_{\theta}{\prod_{i=1}^{N}{p(x_{i}|\theta)}}
$$
由于连乘操作容易出现数值精度问题，且不易优化，因此常常取对数将其转化为累加，得到对数似然$\log{\mathcal{L}(\theta)}$进行等价的计算，寻找使得对数似然函数取最大值的$\hat{\theta}$。此时$\theta$的最大似然估计为
$$
\hat{\theta} = \arg\max_{\theta}{\log{\mathcal{L}(\theta)}} = \arg\max_{\theta}{\sum_{i=1}^{N}{\log{p(x_{i}|\theta)}}}
$$

### **求解步骤**

1. **定义模型**  
   假设数据服从某个分布（如高斯分布、二项分布等），并确定参数 $\theta$。例如：抛硬币实验中，假设正面向上的概率为 $\theta$，则单次试验的概率为 $p(x;\theta) = \theta^x (1-\theta)^{1-x}$，其中 $x \in \{0,1\}$。
   
2. **写出似然函数**：对于观测数据 $D = \{x_1, x_2, ..., x_n\}$，似然函数为：
   $$
   L(\theta; D) = \prod_{i=1}^n \theta^{x_i}(1-\theta)^{1-x_i}
   $$
   
3. **取对数**：对数似然函数为：
   $$
   \ell(\theta; D) = \sum_{i=1}^n \left[x_i \log \theta + (1-x_i)\log(1-\theta)\right]
   $$
   
4. **求导并解方程**：对 $\theta$ 求导并令导数为0，找到极值点：
   $$
   \frac{d\ell}{d\theta} = \sum_{i=1}^n \left(\frac{x_i}{\theta} - \frac{1-x_i}{1-\theta}\right) = 0
   $$
   解得：
   $$
   \hat{\theta}_{\text{MLE}} = \frac{1}{n} \sum_{i=1}^n x_i
   $$
   即正面向上的频率。
   
5. **验证极值**：通常通过二阶导数或边界条件验证是否为最大值。

### **高斯分布的MLE示例**

假设数据服从正态分布 $N(\mu, \sigma^2)$，参数 $\theta = (\mu, \sigma^2)$。  
- 似然函数：
  $$
  L(\mu, \sigma^2; D) = \prod_{i=1}^n \frac{1}{\sqrt{2\pi \sigma^2}} \exp\left(-\frac{(x_i-\mu)^2}{2\sigma^2}\right)
  $$
- 对数似然函数：
  $$
  \ell(\mu, \sigma^2; D) = -\frac{n}{2} \log(2\pi \sigma^2) - \frac{1}{2\sigma^2} \sum_{i=1}^n (x_i-\mu)^2
  $$
- 求导并解得：
  $$
  \hat{\mu}_{\text{MLE}} = \frac{1}{n} \sum_{i=1}^n x_i, \quad \hat{\sigma}^2_{\text{MLE}} = \frac{1}{n} \sum_{i=1}^n (x_i - \hat{\mu})^2
  $$

### 误差

很显然，点估计$\hat{\theta}$是数据集$\mathcal{D}$的函数。由于数据$\mathcal{D}$是某个分布的采样，$\hat{\theta}$本身也是随机变量，因此需要利用$\hat{\theta}$的一些数字特征评估估计的准确程度。下面以一维的参数为例。

**定义5（无偏估计）**：设$\hat{\theta}$是$\theta$的一个估计，$\theta$的参数空间为$\Theta$，若$\forall\theta\in\Theta$，都有$\mathbb{E}[\hat{\theta}] = \theta$，则称$\hat{\theta}$是$\theta$的无偏估计，否则称为有偏估计。

对于无偏估计而言，由于$\mathbb{E}[\hat{\theta}-\theta] = 0$，因此这一估计的系统误差为0，无法通过系统误差判断不同的无偏估计的好坏。常用的方法是用无偏估计的方差衡量无偏估计的优劣，该评估围绕参数真实值的波动越小越好。

**定义6（无偏估计的有效性）**：设$\hat{\theta}_{1}$和$\hat{\theta}_{2}$是$\theta$的两个无偏估计，若$\forall\theta\in\Theta,\text{Var}(\hat{\theta}_{1})\le\text{Var}(\hat{\theta}_{2})$且$\exist\theta\in\Theta$使得不等号严格成立，则称$\hat{\theta}_{1}$比$\hat{\theta}_{2}$更有效。

对于有偏估计而言，往往使用估计值$\hat{\theta}$与参数真实值$\theta$的距离评价估计的好坏。由于二者的距离仍然是一个随机变量，因此取这一随机变量的期望作为指标。常用的距离为二者差值的平方，即均方误差：
$$
\text{MSE}(\hat{\theta}) = \mathbb{E}[(\hat{\theta}-\theta)^{2}]
$$
在这一评价指标下，均方误差越小，表示点估计越好。进一步推导可以得到如下等式：
$$
\begin{aligned}
\text{MSE}(\hat{\theta})&=\mathbb{E}\left[ (\hat{\theta}-\mathbb{E}(\hat{\theta}))+(\mathbb{E}(\hat{\theta})-\theta) \right]^{2}
\\[5pt]
&= \mathbb{E}\left[\left( \hat{\theta}-\mathbb{E}(\hat{\theta}) \right)^{2}\right]+\mathbb{E}\left[\left( \mathbb{E}(\hat{\theta})-\theta \right)^{2}\right]+2\mathbb{E}\left[ \left( \hat{\theta}-\mathbb{E}(\hat{\theta}) \right)\left( \mathbb{E}(\hat{\theta})-\theta \right) \right]
\\[5pt]
&= \text{Var}(\hat{\theta})+\left( \mathbb{E}(\hat{\theta})-\theta \right)^{2}+2\left( \mathbb{E}(\hat{\theta})-\theta \right)\left( \mathbb{E}(\hat{\theta})-\mathbb{E}(\hat{\theta}) \right)
\\[5pt]
&= \text{Var}(\hat{\theta})+\left( \mathbb{E}(\hat{\theta})-\theta \right)^{2}
\end{aligned}
$$
因此，均方误差等于点估计的方差与点估计偏差的平方之和。对于无偏估计而言，可得$\text{MSE}(\hat{\theta}) = \text{Var}(\hat{\theta})$，此时基于方差评价无偏估计与基于均方误差评价无偏估计是等价的。

# 贝叶斯推断

贝叶斯推断（Bayesian Inference）是统计学中一种基于**贝叶斯定理**的参数估计和推断方法，其核心思想是：**将参数视为随机变量，通过观测数据不断更新参数的概率分布**。与最大似然估计（MLE）和最大后验估计（MAP）不同，贝叶斯方法不仅给出参数的点估计，还提供参数的完整概率分布（后验分布），从而量化参数的不确定性。

### 贝叶斯定理的核心

贝叶斯定理的数学形式为：
$$
p(\theta \mid D) = \frac{p(D \mid \theta) p(\theta)}{p(D)}
$$
其中：
- $ p(\theta \mid D) $：**后验分布**（Posterior），即给定数据 $ D $ 时参数 $ \theta $ 的概率分布。
- $ p(D \mid \theta) $：**似然函数**（Likelihood），即在参数 $ \theta $ 下数据 $ D $ 出现的概率。
- $ p(\theta) $：**先验分布**（Prior），即参数 $ \theta $ 的先验知识（在观测数据前的信念）。
- $ p(D) $：**证据**（Evidence），是数据 $ D $ 的边缘概率，可视为归一化常数：
  $$
  p(D) = \int p(D \mid \theta) p(\theta) d\theta
  $$

贝叶斯方法的核心目标是**通过数据 $ D $ 更新先验分布 $ p(\theta) $，得到后验分布 $ p(\theta \mid D) $**

### 贝叶斯推断的步骤

1. **选择先验分布 $ p(\theta) $** ：根据领域知识或无信息先验（如均匀分布）定义参数的初始分布。
   
2. **定义似然函数 $ p(D \mid \theta) $** ：假设数据服从某个概率模型（如高斯分布、伯努利分布等）。
   
3. **计算后验分布 $ p(\theta \mid D) $** ：利用贝叶斯定理结合先验和似然，求解后验分布：
   $$
   p(\theta \mid D) \propto p(D \mid \theta) p(\theta)
   $$
   相比于先验$p(\theta)$，后验分布$p(\theta|\mathcal{D})$蕴涵了从数据$\mathcal{D}$中观测到的信息，刻画了关于参数$\theta$更新后的概率分布。与频率的方法相比，前者将$\theta$看成未知参数，其值是通过某个估计确定的；而这个估计本身的不确定性是通过考虑数据集$\mathcal{D}$的分布刻画的。在贝叶斯推断中，模型的不确定性是通过参数$\theta$的分布刻画的，而数据集$\mathcal{D}$是给定的。

### 常见应用和方法

后验分布综合考虑了先验信息和数据，利用后验分布$p(\theta|\mathcal{D})$可以完成多个基本任务，包括预测、模型选择以及基于后验分布的点估计等等。

**预测**：对新数据 $ x_{\text{new}} $ 的预测通过积分后验分布获得：
$$
\begin{aligned}
p(x_{\text{new}} \mid D) &= \int{p(x_{\text{new}},\theta\mid D)d\theta}
\\[5pt]
&= \int{p(x_{\text{new}}\mid\theta,D)\cdot p(\theta\mid D)d\theta}
\\[5pt]
&= \int p(x_{\text{new}} \mid \theta)\cdot p(\theta \mid D) d\theta
\end{aligned}
$$
其中最后一个等式是因为在给定模型参数的情况下，数据是独立同分布的，因此，$x_{\text{new}}$与$\mathcal{D}$满足在给定$\theta$下的条件独立性。

**模型选择**：模型选择是统计和机器学习中的一个重要任务，贝叶斯方法还可以用于模型选择。对一个特定的模型族$\mathcal{M}$，可以计算其边缘似然：
$$
p(\mathcal{D|M}) = \int{p(\mathcal{D}|\theta)p(\theta|\mathcal{M})d\theta}
$$
其中$p(\theta|\mathcal{M})$通常是均匀分布。这一模型似然函数可用于选择更简单的模型。

**最大后验估计**：在给定参数$\theta$的先验分布和似然函数之后，可以得到其后验分布。与最大似然估计不同，最大后验估计是求后验函数式的最大值：
$$
\hat{\theta}_{\text{MAP}} = \arg\max_{\theta} \left[ p(\mathcal{D} \mid \theta) p(\theta) \right]
$$
最大后验估计在考虑似然函数最大的同时还加入了先验函数的信息。

### 在线贝叶斯推断

贝叶斯推断的一个良好特性是可以进行增量式在线更新。具体地，在很多应用场景下，数据时逐渐增加的。记每次给的数据为$\mathcal{D}_{i},\;i=1,2\dots,m$，设初始分布为先验分布，那么当前轮次$t$的贝叶斯后验分布为$p(\theta|\mathcal{D}_{1},\mathcal{D}_{2},\dots,\mathcal{D}_{t})$。利用贝叶斯公式，可以得到：
$$
p(\theta|\mathcal{D}_{1},\mathcal{D}_{2},\dots,\mathcal{D}_{t})\propto p(\theta|\mathcal{D}_{1},\mathcal{D}_{2},\dots,\mathcal{D}_{t-1})\cdot p(\mathcal{D}_{t}|\theta)
$$
其中$p(\theta|\mathcal{D}_{1},\mathcal{D}_{2},\dots,\mathcal{D}_{t-1})$为上一轮次的后验分布。可以看到，上一轮次的后验分布实际上可以看作当前轮次的先验分布。

## 最大后验估计(MAP)

最大后验估计（Maximum A Posteriori Estimation, MAP）是贝叶斯统计框架中的一种参数估计方法，其核心思想是：**在给定观测数据的条件下，寻找后验概率最大的参数值**。与最大似然估计（MLE）不同，MAP不仅依赖于数据本身，还引入了参数的先验分布（Prior Distribution），从而结合了先验知识与数据信息。

MAP 的目标是找到使后验概率 $ p(\theta \mid D) $ 最大的参数 $ \theta $：
$$
\hat{\theta}_{\text{MAP}} = \arg\max_{\theta} p(\theta \mid D)
$$

由于 $ p(D) $ 是常数，可以忽略，因此等价于：
$$
\hat{\theta}_{\text{MAP}} = \arg\max_{\theta} \left[ p(D \mid \theta) p(\theta) \right]
$$

### MAP 与 MLE 的关系

- **MLE 的目标**：最大化似然函数 $ p(D \mid \theta) $。
- **MAP 的目标**：最大化后验概率 $ p(\theta \mid D) $，即同时考虑似然 $ p(D \mid \theta) $ 和先验 $ p(\theta) $。

如果先验 $ p(\theta) $ 是均匀分布（即无信息先验，Uniform Prior），则 MAP 等价于 MLE：
$$
\hat{\theta}_{\text{MAP}} = \arg\max_{\theta} \left[ p(D \mid \theta) \cdot \text{Uniform}(\theta) \right] = \arg\max_{\theta} p(D \mid \theta) = \hat{\theta}_{\text{MLE}}
$$

### 数学推导

假设数据独立同分布（i.i.d.），且参数 $ \theta $ 的先验分布为 $ p(\theta) $，则 MAP 的优化目标为：
$$
\hat{\theta}_{\text{MAP}} = \arg\max_{\theta} \left[ \prod_{i=1}^n p(x_i \mid \theta) \cdot p(\theta) \right]
$$
取对数后转化为：
$$
\hat{\theta}_{\text{MAP}} = \arg\max_{\theta} \left[ \sum_{i=1}^n \log p(x_i \mid \theta) + \log p(\theta) \right]
$$
即：
$$
\hat{\theta}_{\text{MAP}} = \arg\max_{\theta} \left[ \ell(\theta; D) + \log p(\theta) \right]
$$
其中 $ \ell(\theta; D) $ 是对数似然函数。

### 示例：抛硬币实验

假设我们通过抛硬币实验估计正面向上的概率 $ \theta \in [0,1] $，数据 $ D = \{x_1, x_2, ..., x_n\} $，其中 $ x_i \in \{0,1\} $（1表示正面，0表示反面）。

#### MLE 解法

- 似然函数：$ p(D \mid \theta) = \prod_{i=1}^n \theta^{x_i}(1-\theta)^{1-x_i} $
- 对数似然：$ \ell(\theta; D) = \sum_{i=1}^n \left[ x_i \log \theta + (1-x_i)\log(1-\theta) \right] $
- MLE 解：$ \hat{\theta}_{\text{MLE}} = \frac{1}{n} \sum_{i=1}^n x_i $

#### MAP 解法

- 先验分布：假设 $ \theta \sim \text{Beta}(\alpha, \beta) $，其概率密度函数为：
  $$
  p(\theta) = \frac{1}{B(\alpha, \beta)} \theta^{\alpha-1}(1-\theta)^{\beta-1}
  $$

- 对数先验：$ \log p(\theta) = (\alpha-1)\log \theta + (\beta-1)\log(1-\theta) + \text{常数} $

- MAP 优化目标：
  $$
  \begin{aligned}
  \hat{\theta}_{\text{MAP}} &=\arg\max_{\theta}\left[\sum_{i=1}^{n}{\ell(\theta;D)+\log{p(\theta)}}\right]
  \\[5pt]
  &= \arg\max_{\theta} \left[ \sum_{i=1}^n \left( x_i \log \theta + (1-x_i)\log(1-\theta) \right) + (\alpha-1)\log \theta + (\beta-1)\log(1-\theta) \right]
  \end{aligned}
  $$

- 求导并令导数为0：
  $$
  \frac{d}{d\theta} \left[ \sum_{i=1}^n x_i \log \theta + \sum_{i=1}^n (1-x_i)\log(1-\theta) + (\alpha-1)\log \theta + (\beta-1)\log(1-\theta) \right] = 0
  $$
  解得：
  $$
  \hat{\theta}_{\text{MAP}} = \frac{\sum_{i=1}^n x_i + \alpha - 1}{n + \alpha + \beta - 2}
  $$

#### 结果分析

- 当 $ \alpha = \beta = 1 $（均匀先验），MAP 退化为 MLE：
  $$
  \hat{\theta}_{\text{MAP}} = \frac{\sum_{i=1}^n x_i}{n}
  $$

- 当 $ \alpha = 2, \beta = 2 $（偏好中间值的先验），MAP 估计值会向 $ 0.5 $ 偏移：
  $$
  \hat{\theta}_{\text{MAP}} = \frac{\sum_{i=1}^n x_i + 1}{n + 2}
  $$
